import time
import tensorflow as tf
tf.python.control_flow_ops = tf

import numpy as np
import pandas as pd
import preprocess
from preprocess import Preprocess

import cv2
from sklearn.utils import shuffle
from scipy.misc import imread, imsave

from model import get_model
from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint
from keras.models import model_from_json
from keras.callbacks import LambdaCallback, TensorBoard
import argparse
import random

def gen_transforms(l, augment_transform):
	if augment_transform.startswith('c'):
		st = l.steering
		image    = imread(l.center)
		image_f  = cv2.flip(image, flipCode = 1) 
	elif augment_transform.startswith('r'):
		st       = l.steering + l.steering_bias_right
		image    = imread(l.right)
		image_f  = cv2.flip(image, flipCode = 1) 
	elif augment_transform.startswith('l'):
		st       = l.steering + l.steering_bias_left
		image    = imread(l.left)			
		image_f  = cv2.flip(image, flipCode = 1) 
	return (image, shadow(image), image_f, shadow(image_f), st, st, -st, -st)

# GENERATOR
# 
# yield images and steering angles for training and validation
# each entry in the log contains the information in the CSV file
# generated by the simulator and 3 extra parameters:
#
# - steering_bias_left:  amount of steering compensation for L camera
# - steering_bias_right: amount of steering compensation for R camera
# - augment_transforms:  string containing allowed transformations:
#
#   c   = center
#   l   = left camera
#   r   = right camera
# 
# In addition for each augmented image another one is created by applying
# a random shadow 
#
# So if an entry has 'c cf l r lf rf' augment_transforms a total of
# 12 images will be generated 
#
def generator(log, validation = False):
	
	save_counter = 0
	
	while True:
		log = shuffle(log)

		if validation == False:
			print("Generator loop") # print to make sure we start yielding accross each epoch (debug only)

		for i, ll in log.groupby(np.arange(len(log)) // BS):

			# incoming size of images is 160x320
			images              = np.empty([0, 160, 320, 3], dtype=np.uint8)
			augmented_steerings = np.empty([0, 1], dtype=np.float32)

			work_l = []
			work_a = []
			for j,l in ll.iterrows():
				if validation == True:
					center = imread(l.center)
					st = l.steering
					images 				= np.vstack((images, [center]))
					augmented_steerings = np.vstack((augmented_steerings, [st]))
				else:
					augment_transforms = l.augment_transforms.split()
					work_l.extend([l] * len(augment_transforms))
					work_a.extend(augment_transforms)

			if (validation == False):

				# nvidia-smi reports low GPU usage (<50%) so I tried increasing
				# batch size... but as I increased batch size EPOCH times grew
				# this led me to think we were CPU-bound, so I experimented 
				# with multi-threading.
				# 
				# Experiment was a failure. leave to False since MT is significantly 
				# slower than ST still don't know WHY. I also tried this generator in 
				# multiprocess mode (see Keras dox: nb_worker, pickle_safe) but results 
				# in slower behavior too.
				multi_thread = False

				if multi_thread:
					from multiprocessing.dummy import Pool as ThreadPool 
					from multiprocessing import cpu_count

					pool = ThreadPool(cpu_count())
					results = pool.starmap(gen_transforms, zip(work_l, work_a))
					pool.close()
					pool.join()
				else:
					results = []
					for w_l, w_a in zip(work_l, work_a):
						results.append(gen_transforms(w_l, w_a))
				for r in results:
					images 				= np.vstack((images, 			  [r[0]], [r[1]], [r[2]], [r[3]]))
					augmented_steerings = np.vstack((augmented_steerings, [r[4]], [r[5]], [r[6]], [r[7]]))

			images_processed = np.empty([0, Preprocess.sizey, Preprocess.sizex, 3], dtype=np.uint8)

			save_counter += 1
			for inum,im in enumerate(images):
				if (save_counter % 1000) == 0:
					imsave( "train-{}.jpg".format(inum), im)
				images_processed = np.vstack((images_processed, [Preprocess.preprocess(im)]))

			(images_processed, augmented_steerings) = shuffle(images_processed, augmented_steerings)

			yield (images_processed, np.clip(augmented_steerings, -1., 1.))

# balances dataset: take as much as bin_n items for each bin
# it doesnt take into account the augmented steerings 
# credit: http://navoshta.com/end-to-end-deep-learning/
def balance(log):
	balanced = pd.DataFrame()   # Balanced dataset
	bins =  1000                # N of bins
	bin_n = 200                 # N of examples to include in each bin (at most)

	start = 0
	for end in np.linspace(0, 1, num=bins):  
		df_range = log[(np.absolute(log.steering) >= start) & (np.absolute(log.steering) < end)]
		range_n = min(bin_n, df_range.shape[0])
		if range_n > 0:
			balanced = pd.concat([balanced, df_range.sample(range_n)])
		start = end
	return balanced

# apply random shadow to image
# loosely based on: http://navoshta.com/end-to-end-deep-learning/
def shadow(image):
	max_shadow_sides = np.random.randint(2,10)
	h, w = image.shape[0], image.shape[1]
	#y = np.random.choice(h//shadow_sides, shadow_sides, replace=False)
	y = np.append(np.unique(np.random.randint(1, h, size=max_shadow_sides)),h)
	shadow_sides=len(y)
	y[1:] = y[1:]-y[0:-1]
	x = np.random.choice(w, shadow_sides+1, replace=False)
	hii = 0
	shadow_image = np.array(image)
	side = random.choice([True, False])
	shadow = (np.random.random_sample() * 0.1 + 0.3)
	for n in range(shadow_sides):
		k = y[n] / (x[n+1] - x[n])
		b = - k * x[n]
		for hi in range(y[n]):
			c = int((hi - b) / k)
			if side:
				shadow_image[hii, c:, :] = (image[hii, c:, :] * shadow).astype(np.uint8)
			else:
				shadow_image[hii, :c, :] = (image[hii, :c, :] * shadow).astype(np.uint8)
			hii += 1
	return shadow_image

# ***** main loop *****

if __name__ == "__main__":

	BS = 1

	parser = argparse.ArgumentParser(description='Train behavioral cloning udacity CarND P3')
	parser.add_argument('centerdir', type=str, default='driving-centered', help='Directory name of training data for CENTERED driving')
	parser.add_argument('leftdir', type=str, default='driving-left', help='Directory name of training data for driving on the LEFT')
	parser.add_argument('rightdir', type=str, default='driving-right', help='Directory name of training data for driving on the RIGHT')
	parser.add_argument('model', type=str, default="comma", help='Model (nvidia, comma)')
	args = parser.parse_args()

	current_model = args.model
	print('Using model: ',current_model)

	# Train the model
	# History is a record of training loss and metrics
	center_log = pd.read_csv(args.centerdir+'/driving_log.csv')
	left_log   = pd.read_csv(args.leftdir+'/driving_log.csv')
	right_log  = pd.read_csv(args.rightdir+'/driving_log.csv')
	
	sk_right_dir = 'driving-skewed-right-15'
	sk_right_log  = pd.read_csv(sk_right_dir+'/driving_log.csv')

	sk_left_dir = 'driving-skewed-left-15'
	sk_left_log  = pd.read_csv(sk_left_dir+'/driving_log.csv')

	track2_dir   = 'track2-validation'
	track2_log   = pd.read_csv(track2_dir+'/driving_log.csv')
	
	for i in ['left', 'right', 'center']:
		center_log[i]   = args.centerdir + '/' + center_log[i].str.strip()
		left_log[i]     = args.leftdir   + '/' + left_log[i].str.strip()
		right_log[i]    = args.rightdir  + '/' + right_log[i].str.strip()
		sk_right_log[i] = sk_right_dir   + '/' + sk_right_log[i].str.strip()
		sk_left_log[i]  = sk_left_dir    + '/' + sk_left_log[i].str.strip()
		track2_log[i]   = track2_dir     + '/' + track2_log[i].str.strip()

	steering_bias = 0.2

	# driving in the center, steering follows the road
	#
	center_log['steering_bias_left']  =  steering_bias
	center_log['steering_bias_right'] = -steering_bias
	center_log['augment_transforms'] = "c l r" 

	# driving at the left edge of the road, steering follows the road
	#
	left_log.steering  = left_log.steering + 0.7
	left_log['steering_bias_left']  =   steering_bias
	left_log['steering_bias_right'] =  -steering_bias
	left_log['augment_transforms'] = "c r"

	# driving at the right edge of the road, steering follows the road
	#
	right_log.steering = right_log.steering - 0.7
	right_log['steering_bias_left']  =   steering_bias
	right_log['steering_bias_right'] =  -steering_bias
	right_log['augment_transforms'] = "c l"
	
	# fragments of attempting to drive out of the road, pointing ~15 deg to the right
	# steering is 0. 
	sk_right_log.steering -= 0.6
	sk_right_log['steering_bias_left'] =   steering_bias
	sk_right_log['steering_bias_right'] = -steering_bias
	sk_right_log['augment_transforms'] = "c r l"

	# fragments of attempting to drive out of the road, pointing ~15 deg to the left
	# steering is 0
	sk_left_log.steering += 0.6
	sk_left_log['steering_bias_left'] =   steering_bias
	sk_left_log['steering_bias_right'] = -steering_bias
	sk_left_log['augment_transforms'] = "c l r"


	# driving in the center, steering follows the road
	#
	#track2_log['augment_transforms'] = "c" 


	cb   = ModelCheckpoint(current_model + ".h5", monitor='val_loss', save_best_only=True)
	cbtb = TensorBoard(write_images=True)

	model = get_model(current_model)

	with open(current_model + ".json", "w") as file:
		file.write(model.to_json())

	driving_log = pd.concat([center_log, left_log, right_log, sk_right_log, sk_left_log])
	train_log, validate_log = train_test_split(driving_log, test_size=0.20)

	print("Samples in unbalanced train set:",      train_log.shape[0])
	print("Samples in unbalanced validation set:", validate_log.shape[0]) #only track #1

	b_train_log    = balance(train_log)
	b_validate_log = pd.concat([balance(validate_log), balance(track2_log)])
	print("Samples in balanced train set:",      b_train_log.shape[0])
	print("Samples in balanced validation set:", b_validate_log.shape[0])
	history = model.fit_generator(generator(b_train_log), 
				nb_epoch=100, 
				samples_per_epoch = 4*(b_train_log.augment_transforms.str.split().str.len()).sum(),
				validation_data = generator(b_validate_log, validation=True),
				nb_val_samples = b_validate_log.shape[0],
				callbacks = [cb, cbtb])

